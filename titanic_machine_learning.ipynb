{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf509dd-1a11-4422-b6e3-03d330de82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub\n",
    "#!是不以代码运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172be26d-a6eb-4dc9-9431-c298b872d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = kagglehub.dataset_download(\"user-name/dataset-name\")\n",
    "#model_path = kagglehub.model_download(\"publisher/model/framework/variation\")\n",
    "\n",
    "\n",
    "#files = os.listdir(path)\n",
    "#full_path = os.path.join(path, \"my_file.csv\")\n",
    "#exists = os.path.exists(full_path)\n",
    "#os.mkdir(\"my_new_folder\")\n",
    "\n",
    "\n",
    "#df = pd.read_csv(full_path_to_file)\n",
    "#df = pd.read_excel(\"my_data.xlsx\", sheet_name=\"Sheet1\")\n",
    "#df.head()  前5行\n",
    "#df.tail()  后5行\n",
    "#df.shape  N行N列\n",
    "#df.info()  每一列的名称 (Column)。每一列的非空值数量 (Non-Null Count)（帮您快速发现缺失值）。每一列的数据类型 (Dtype)\n",
    "#df.describe()  统计描述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9a09e5-f756-4583-9706-520000197a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"brendan45774/test-file\")\n",
    "#函数成功完成后，它会返回 (Return) 一个值。在这个例子中，它返回的值就是**“数据集被下载到您电脑上的哪个位置”的路径**\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea29566b-53af-4293-a67b-dc46789a9b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "# 1. 再次获取数据集文件夹路径（这将从缓存加载，非常快）\n",
    "path = kagglehub.dataset_download(\"heptapod/titanic\")\n",
    "\n",
    "# 2. 【关键修正】我们使用侦察到的正确文件名\n",
    "file_name = \"train_and_test2.csv\"\n",
    "\n",
    "# 3. 构建完整的文件路径\n",
    "full_path_to_file = os.path.join(path, file_name)\n",
    "\n",
    "print(f\"成功找到文件，正在读取: {full_path_to_file}\")\n",
    "\n",
    "# 4. 【关键步骤】使用 Pandas 读取 CSV 文件！\n",
    "df = pd.read_csv(full_path_to_file)\n",
    "\n",
    "# 5. 验证是否成功：打印数据的前5行\n",
    "print(\"--- Pandas 读取数据成功！这是数据的前5行：---\")\n",
    "\n",
    "df.info()\n",
    "\n",
    "\"\"\"\n",
    "先df.info()【column/Non-Null Count/Type】/\n",
    "后df.describe()描述性统计/\n",
    "df.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ad179-e56a-4868-893b-08cb4b69adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c9762-1b77-4679-a2bb-40e70b401b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "总行数： 您的数据集中总共有 1309 条记录 (entries)。\n",
    "缺失值发现： 您做得非常好！您可以看到几乎所有列都是 1309 non-null，除了：\n",
    "24 Embarked 1307 non-null float64 这准确地告诉我们，在 Embarked（登船港口）这一列中，有 1309 - 1307 = 2 行是缺失数据。\n",
    "数据质量问题：\n",
    "“垃圾”列： 您有没有注意到所有那些 zero, zero.1, zero.2... 等列？这看起来像是原始数据处理不当，这些列很可能对我们毫无用处，我们稍后需要把它们删除。\n",
    "“可疑”列名： 最后一行 2urvived 看起来很像一个拼写错误，它几乎可以肯定就是我们要预测的 Survived（生还）列。我们也需要重命名它。\n",
    "\n",
    "综合 df.info() 和 df.describe() 的所有发现，我们现在可以制定一个清晰的清洗计划了。这是阶段一：任务 2 (Pandas) 中最关键的一步。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fcf0ce-fce2-4a4f-9d7f-5d41ed4cc5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "我们的“待办事项”：\n",
    "删除“垃圾”列： zero, zero.1, zero.2 ... zero.18 这些列显然是无用数据，会干扰分析。\n",
    "重命名“错误”列： 2urvived 那个列名是错的，我们要把它改成 Survived。\n",
    "处理“缺失”数据： Embarked 列有 2 个缺失值，我们要么填充它们，要么删除那两行。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4b560-1aed-431d-8cc1-cebe0779c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6ad29-9df6-43d1-bee3-0251ec9121db",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_for_drop = [col for col in df if 'zero' in col]\n",
    "#相当于返回一个列表，存储了要移除的列（column）\n",
    "#{}表示的是字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574fe39-bee8-463e-9241-bcfa9ad2d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.drop(columns = col_for_drop)\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052780c2-36f5-48b6-acb9-b859bf6ca48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#重命名列\n",
    "df_cleaned = df_cleaned.rename(columns = {'2urvived':'survived'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b96db-736a-4771-aaeb-77f56ba0f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e158b49-573f-4dc1-8372-9b1e0bd46414",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "现在删除embarked的两个缺省值\n",
    "df.dropna()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa999792-3bf2-414f-b8c6-98729798712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset=['Embarked'] 的意思是：只检查 'Embarked' 这一列的缺失情况\n",
    "df_cleaned = df_cleaned.dropna(subset = ['Embarked'])\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a172b1-7fa9-48d9-bb6e-7996929df945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理代码结束，进入画图环节\n",
    "#单变量绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47c651d-dec1-43e6-8730-9d879bbc638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 导入库\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# 假设你的 df_cleaned 已经加载好了\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 步骤 3 在这里！在重启 Kernel 后，把设置代码放在最前面\n",
    "# ----------------------------------------------------\n",
    "# 使用 'SimHei' (黑体) 是最保险的选择\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] \n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# 2. 设置主题\n",
    "sns.set_theme(style=\"darkgrid\") \n",
    "\n",
    "# 3. 创建图表\n",
    "print(\"--- 正在生成图表 (如果这是重启后第一次，可能会稍慢)... ---\")\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=df_cleaned, x='survived') # 假设你已经修复了 '2urvived ' 列名\n",
    "\n",
    "# 4. 添加标题\n",
    "plt.title('生还情况计数 (0 = 遇难, 1 = 生还)')\n",
    "plt.xlabel('是否生还')\n",
    "plt.ylabel('人数')\n",
    "\n",
    "# 5. 显示图表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65f5927-1f70-4b67-9545-bb64e40ebcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#双变量绘图\n",
    "df_cleaned.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f492ba2-e3aa-48d0-bc20-9d04e9cdb5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "sns.kdeplot(\n",
    "    data = df_cleaned,\n",
    "    x = 'Age',\n",
    "    fill = True,\n",
    "    alpha = 0.5,\n",
    "    hue = 'Survived_str',\n",
    "    common_norm = False\n",
    ")\n",
    "plt.show()\n",
    "\"\"\"\n",
    "1. 什么是 KDE 的“归一化” (norm)？\n",
    "kdeplot（核密度估计图）画的是概率密度 (Density)。\n",
    "\n",
    "在概率论中，一个完整的概率分布，其曲线下方的总面积必须等于 1（代表 100% 的概率）。\n",
    "\n",
    "“归一化” (Normalization) 就是一个缩放 (Scaling) 的过程，它调整曲线的高度，以确保其下方的总面积正好等于 1。\n",
    "\n",
    "2. common_norm 解决了什么问题？\n",
    "这个问题只在您同时使用 hue 时才出现。\n",
    "\n",
    "当您使用 hue='Survived_str' 时，您在同一张图上画了两条 KDE 曲线：\n",
    "\n",
    "“存活”者的年龄分布\n",
    "\n",
    "“未存活”者的年龄分布\n",
    "\n",
    "在泰坦尼克号数据集中，这两个组的人数是“不平等”的（例如，未存活的人数 549 人，存活的人数 342 人）。\n",
    "\n",
    "common_norm 参数就是用来决定：我们应该如何处理这种“不平等”的人数来进行归一化？\n",
    "\n",
    "3. 两种选择：True vs. False\n",
    "选项 A: common_norm = True (默认值)\n",
    "含义： “共同归一化”。\n",
    "\n",
    "做法： Seaborn 会把两条曲线当作一个整体来归一化。所有曲线下方的总面积加起来等于 1。\n",
    "\n",
    "结果： 因为“未存活”组的人数更多，它的曲线天生就会更高（面积更大）；“存活”组的曲线天生就会更矮（面积更小）。\n",
    "\n",
    "缺点： 这使得比较两条曲线的**“形状”**变得非常困难。您看到的高度差异，既包含了“形状”的差异，也包含了“人数”的差异，两者混在了一起。\n",
    "\n",
    "选项 B: common_norm = False (您代码中的选择)\n",
    "含义： “独立归一化”。\n",
    "\n",
    "做法： Seaborn 会分开处理这两条曲线。\n",
    "\n",
    "它拿出“存活”组的数据，画出曲线，并将其缩放，使**“存活”曲线下的面积等于 1**。\n",
    "\n",
    "它拿出“未存活”组的数据，画出曲线，并将其缩放，使**“未存活”曲线下的面积也等于 1**。\n",
    "\n",
    "结果： 两条曲线现在站在了**“同一起跑线”**上。它们的高度（密度）现在可以直接比较了。\n",
    "\n",
    "优点： 这种方法完全消除了“总人数不同”带来的干扰。您现在可以非常清晰地比较两条曲线的“形状”。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5772dc8-a85f-4fb6-820d-dc43224262b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "知识点复盘\n",
    "这是一个非常好的习惯！我们已经走过了整个“数据分析”阶段，即将进入“机器学习”阶段。在此时复盘是最佳时机。\n",
    "\n",
    "您从一个“Python 新手”开始，现在已经掌握了数据分析师的全套核心技能。我们来一起复盘您的知识体系。\n",
    "\n",
    "第一阶段复盘：数据分析师的核心技能\n",
    "您的学习旅程分为三个主要部分：环境配置 -> 数据清洗 -> 数据可视化。\n",
    "\n",
    "1. 环境与工具（我们如何“开工”）\n",
    "这是您解决“技术问题”的部分，是所有分析的基础。\n",
    "\n",
    "Jupyter Notebook:\n",
    "\n",
    "核心: 您的“交互式”工作台。它允许您一次运行一小块代码 (Cell)，并立刻看到结果（表格、图表、错误信息），非常适合数据分析。\n",
    "\n",
    "知识点: !pip install ...（用于安装新库）、Kernel -> Restart（用于在安装后“刷新”环境）。\n",
    "\n",
    "Kaggle API 与库 (Modules):\n",
    "\n",
    "核心: API 是“服务员”，让您的代码可以从 Kaggle 服务器“点菜”（下载数据）。\n",
    "\n",
    "知识点 (排错):\n",
    "\n",
    "ModuleNotFoundError: 错误原因是“库没有安装”。\n",
    "\n",
    "!pip install [库名]: 解决方案（例如 !pip install kagglehub）。\n",
    "\n",
    "ImportError (Pillow 损坏): 错误原因是“库已损坏”。\n",
    "\n",
    "!pip install --force-reinstall [库名]: 强制修复的解决方案。\n",
    "\n",
    "Python 基础语法:\n",
    "\n",
    "大小写敏感: 您亲自发现并修复了 ValueError: ... 'age' ... does not appear，因为正确的列名是 'Age'。\n",
    "\n",
    "临时变量: 您理解了 [col for col in ...] 中的 col 只是一个程序员自己命名的“代号”。\n",
    "\n",
    "2. Pandas：您的“数据瑞士军刀”（任务 1 & 2）\n",
    "这是您整个学习阶段最核心的部分。您学会了如何“驯服”一个原始的数据集。\n",
    "\n",
    "读取数据 (Loading):\n",
    "\n",
    "pd.read_csv(filepath): 将 CSV 文件加载为 DataFrame。\n",
    "\n",
    "FileNotFoundError: 您学会了如何通过 os.listdir() 和 os.path.join() 来“侦察”并找到正确的文件路径。\n",
    "\n",
    "检查数据 (Inspecting):\n",
    "\n",
    "df.head(): “它长什么样？”（快速看前 5 行）。\n",
    "\n",
    "df.info(): “它的健康状况如何？”（核心！ 用于查看数据类型 Dtype 和发现缺失值 Non-Null Count）。\n",
    "\n",
    "df.describe(): “它的统计摘要是什么？”（查看平均值 mean、最大/小值 max/min，帮您发现异常）。\n",
    "\n",
    "清洗数据 (Cleaning):\n",
    "\n",
    "删除列 (Drop Columns): df.drop(columns=['zero.1', 'zero.2', ...])\n",
    "\n",
    "重命名列 (Rename): df.rename(columns={'2urvived': 'Survived'})\n",
    "\n",
    "处理缺失值: df.dropna(subset=['Embarked'])\n",
    "\n",
    "您的关键理解: 您正确地总结出，这会删除 Embarked 为空的整行 (Row)，而不是删除列 (Column)。\n",
    "\n",
    "3. 可视化 (Seaborn & Matplotlib)（任务 3）\n",
    "您学会了如何用图表“讲故事”和“发现规律”。\n",
    "\n",
    "中文显示问题:\n",
    "\n",
    "原因: matplotlib 默认字体不包含中文。\n",
    "\n",
    "解决: plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']（或 SimHei），以指定一个中文字体。\n",
    "\n",
    "您掌握的图表类型:\n",
    "\n",
    "sns.countplot (计数图) - (分析“类别”):\n",
    "\n",
    "单变量: x='Survived' (回答“是什么？” -> 发现遇难者很多)\n",
    "\n",
    "双变量: x='Sex', hue='Survived' (回答“为什么？” -> 发现性别是关键)\n",
    "\n",
    "您的核心技能: 您掌握了 hue (色调) 参数，这是关系分析中最重要的工具。\n",
    "\n",
    "sns.histplot (直方图) - (分析“数值”):\n",
    "\n",
    "x='Age' (回答“分布如何？” -> 发现 20-30 岁的年轻人最多)\n",
    "\n",
    "sns.kdeplot (密度图) - (对比“数值”):\n",
    "\n",
    "x='Age', hue='Survived' (回答“数值关系如何？” -> 证明了“儿童优先”的原则)\n",
    "\n",
    "4. 机器学习数据准备（任务 4）\n",
    "这是您从“分析师”转向“建模者”的关键一步。\n",
    "\n",
    "核心理念: 机器学习模型只懂数字，并且不懂“类别”的逻辑（例如 Pclass=3 并不“大于” Pclass=1）。\n",
    "\n",
    "您的关键发现: 您自己发现 Pclass (1, 2, 3) 必须像 Embarked (0, 1, 2) 一样被处理，这个洞察力非常棒！\n",
    "\n",
    "解决方案 (独热编码):\n",
    "\n",
    "pd.get_dummies(df, columns=['Pclass', 'Sex', 'Embarked'])\n",
    "\n",
    "您的关键理解: 您正确地发现，Sex_1, Pclass_2, Pclass_3 这些新列是**由 pd.get_dummies 这个函数“自动生成”**的。\n",
    "\n",
    "最终步骤 (分离 X 和 y):\n",
    "\n",
    "y = df['Survived']: y (目标) 是我们想要预测的那一列。\n",
    "\n",
    "X = df.drop(columns=['Survived', ...]): X (特征) 是我们用来预测的所有“纯数字”输入数据。\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
